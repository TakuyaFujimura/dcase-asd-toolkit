# @package _global_
defaults:
    - override /datamodule: basic
    - override /frontend: dis_beats
    - override /trainer: default


label_dict_path:
  main: "labels/${dcase}/main.json"

model_ver: "all"

trainer:
  max_epochs: 25
  # accumulate_grad_batches: 8

datamodule:
  batch_size: 8

frontend:
  model_cfg:
    extractor_cfg:
      model_cfg:
        ckpt_path: "pretrained_models/beats/BEATs_iter3.pt"
        update_cfg:
          dropout_input: 0.3
    loss_cfg:
      tgt_class: asdit.losses.SCAdaCos
      n_subclusters: 16
      dynamic: false
      trainable: true
    augmentation_cfg_list: []
  optim_cfg:
    tgt_class: torch.optim.AdamW
    lr: 1.0e-4
  lrscheduler_cfg:
    tgt_class: timm.scheduler.CosineLRScheduler
    t_initial: 5001
    lr_min: ${frontend.optim_cfg.lr}
    warmup_t: 5000
    warmup_lr_init: 0
